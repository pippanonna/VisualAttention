{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6464277",
   "metadata": {},
   "source": [
    "# VIsual Attention Project - FIGRIM Dataset\n",
    "Valerijan Matvejev and Hana Ujcic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import cm\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import nbimporter\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "from Achanta import Achanta\n",
    "\n",
    "#path to dataset\n",
    "PATH_DATA = \"C:/Master/PC/VAproject/FIGRIM/FIGRIM\" # path to the dataset\n",
    "PATH_DEEP = \"C:/Master/PC/VAproject/saliency/results/images\" # path to images generated by MSINet\n",
    "\n",
    "\n",
    "# Experiment-dependant constants\n",
    "RESO_X = 1000\n",
    "RESO_Y = 1000\n",
    "FACTOR_X = RESO_X/270\n",
    "FACTOR_Y = RESO_Y/203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8940a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_normalize(x):\n",
    "    \"\"\"Normalizes x to [0, 1]\"\"\"\n",
    "    x = (x - x.min()) / (x.max() - x.min())\n",
    "    return x\n",
    "\n",
    "def sum_normalize(x):\n",
    "    \"\"\"Normalizes x so that it sums to 1\"\"\"\n",
    "    return x / x.sum()\n",
    "\n",
    "\n",
    "def std_normalize(x):\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "def log_density(saliencyMap, eps=np.spacing(1.0)):\n",
    "    \"\"\"Transforms a non probabilistic saliency map into a log density for\n",
    "    further metric computation.\n",
    "\n",
    "    Arguments:\n",
    "        saliencyMap: Grayscale saliency map.\n",
    "    \"\"\"\n",
    "    saliencyMap = saliencyMap - saliencyMap.min()\n",
    "    saliencyMap += eps\n",
    "    saliencyMap /= saliencyMap.sum()\n",
    "    return np.log(saliencyMap)\n",
    "\n",
    "And now, the metrics !\n",
    "\n",
    "def AUC_Borji(saliencyMap, fixationMap, Nsplits=100, stepSize=0.1):\n",
    "    \"\"\"\n",
    "    This measures how well the saliencyMap of an image predicts the ground\n",
    "    truth human fixations on the image.\n",
    "\n",
    "    ROC curve created by sweeping through threshold values at fixed step size\n",
    "    until the maximum saliency map value.\n",
    "    True positive (tp) rate corresponds to the ratio of saliency values\n",
    "    above threshold at fixation locations to the total number of fixation\n",
    "    locations.\n",
    "    False positive (fp) rate corresponds to the ratio of saliency map\n",
    "    values above threshold at random locations to the total number of random\n",
    "    locations (as many random locations as fixations, sampled uniformly from\n",
    "    ALL IMAGE PIXELS), averaging over Nsplits number of selections of\n",
    "    random locations.\n",
    "\n",
    "    :param saliencyMap: numpy array, saliency map\n",
    "    :param fixationMap: numpy array, fixation map (binary matrix)\n",
    "    :param Nsplits: int, number of random splits\n",
    "    :param stepSize: float, size of the step for sweeping through saliency map\n",
    "\n",
    "    :return score: float, AUC Borji score\n",
    "    :return fpr: float, false positive rate\n",
    "    :return tpr: float, true positive rate\n",
    "    \"\"\"\n",
    "    \n",
    "    saliencyMap = range_normalize(saliencyMap)\n",
    "\n",
    "    S = saliencyMap.flatten()\n",
    "    F = fixationMap.flatten()\n",
    "\n",
    "    Sth = S[F > 0]  # saliency map values at fixation locations\n",
    "    Nfixations = len(Sth)\n",
    "    Npixels = len(S)\n",
    "\n",
    "    # For each fixation, sample Nsplits values from anywhere on the saliency map\n",
    "    r = np.random.randint(1, Npixels, size=Nfixations * Nsplits)\n",
    "    randfix = S[r[:]]\n",
    "    randfix = np.reshape(randfix, (Nfixations, Nsplits))\n",
    "\n",
    "    # Calculate AUC per random split (set of random locations)\n",
    "    auc = np.empty(Nsplits)\n",
    "    auc[:] = np.nan\n",
    "    for s in range(Nsplits):\n",
    "        curfix = randfix[:, s]\n",
    "        allthreshes = np.arange(0, np.amax(np.concatenate([Sth, curfix])) + stepSize, stepSize)\n",
    "        allthreshes = allthreshes[::-1]\n",
    "        tpr = np.zeros(len(allthreshes) + 2)\n",
    "        fpr = np.zeros(len(allthreshes) + 2)\n",
    "        tpr[0], tpr[-1] = 0, 1\n",
    "        fpr[0], fpr[-1] = 0, 1\n",
    "        for i in range(len(allthreshes)):\n",
    "            thresh = allthreshes[i]\n",
    "            tpr[i + 1] = (Sth >= thresh).sum() / Nfixations\n",
    "            fpr[i + 1] = (curfix >= thresh).sum() / Nfixations\n",
    "        auc[s] = np.trapz(tpr, x=fpr)\n",
    "    # Average across random splits\n",
    "    score = np.mean(auc)\n",
    "    return score, fpr, tpr\n",
    "\n",
    "def AUC_Judd(saliencyMap, fixationMap, jitter=True):\n",
    "    \"\"\"\n",
    "    This measures how well the saliencyMap of an image predicts the ground\n",
    "    truth human fixations on the image. ROC curve created by sweeping through\n",
    "    threshold values determined by range of saliency map values at fixation\n",
    "    locations.\n",
    "    Uses a uniform non-fixation distribution, i.e. the full saliency map as\n",
    "    nonfixations.\n",
    "\n",
    "    created Tilke Judd, Oct 2009\n",
    "    updated  Zoya Bylinskii, Aug 2014\n",
    "    python-version by Dario Zanca, Jan 2017\n",
    "\n",
    "    true positive (tp) rate correspond to the ratio of saliency map values\n",
    "    above threshold at fixation locations to the total number of fixation\n",
    "    locations, false positive (fp) rate correspond to the ratio of\n",
    "    saliency map values above threshold at all other locations to\n",
    "    the total number of posible other locations (non-fixated image pixels)\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "        saliencyMap: Saliency map image (grayscale)\n",
    "        fixationMap: Ground truth fixations (binary image)\n",
    "        jitter: Whether to add tiny non-zero random constant to all map\n",
    "            locations to ensure ROC can be calculated robustly\n",
    "            (to avoid uniform region)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        score: float\n",
    "            AUC value for the given inputs\n",
    "    \"\"\"\n",
    "    if not np.shape(saliencyMap) == np.shape(fixationMap):\n",
    "        saliencyMap = cv2.resize(saliencyMap, np.shape(fixationMap)[:2][::-1])\n",
    "\n",
    "    # jitter saliency maps that come from saliency models that have a lot of\n",
    "    # zero values.\n",
    "    # If the saliency map is made with a Gaussian then it does not need to be\n",
    "    # jittered as the values are varied and there is not a large patch of the\n",
    "    # same value. In fact jittering breaks the ordering in the small values!\n",
    "    if jitter:\n",
    "        # jitter the saliency map slightly to disrupt ties of the same numbers\n",
    "        saliencyMap = saliencyMap + np.random.random(np.shape(saliencyMap)) / 10**7\n",
    "\n",
    "    saliencyMap = range_normalize(saliencyMap)\n",
    "\n",
    "    if np.isnan(saliencyMap).all():\n",
    "        __logger.debug('NaN saliencyMap')\n",
    "        score = float('nan')\n",
    "        return score\n",
    "\n",
    "    S = saliencyMap.flatten()\n",
    "    F = fixationMap.flatten()\n",
    "\n",
    "    # Sal map values at fixation locations\n",
    "    Sth = S[F > 0]\n",
    "    Nfixations = len(Sth)\n",
    "    Npixels = len(S)\n",
    "\n",
    "    # sort sal map values, to sweep through values\n",
    "    allthreshes = sorted(Sth, reverse=True)\n",
    "\n",
    "    tpr = np.zeros((Nfixations + 2))\n",
    "    fpr = np.zeros((Nfixations + 2))\n",
    "    tpr[0], tpr[-1] = 0, 1\n",
    "    fpr[0], fpr[-1] = 0, 1\n",
    "\n",
    "    for i in range(Nfixations):\n",
    "        thresh = allthreshes[i]\n",
    "        # total number of sal map values above threshold\n",
    "        aboveth = (S >= thresh).sum()\n",
    "        # ratio sal map values at fixation locations above threshold\n",
    "        tpr[i + 1] = float(i + 1) / Nfixations\n",
    "        # ratio other sal map values above threshold\n",
    "        fpr[i + 1] = float(aboveth - i) / (Npixels - Nfixations)\n",
    "\n",
    "    score = np.trapz(tpr, x=fpr)\n",
    "    allthreshes = np.insert(allthreshes, 0, 0)\n",
    "    allthreshes = np.append(allthreshes, 1)\n",
    "\n",
    "    return score, fpr, tpr\n",
    "\n",
    "def kl_divergence(saliencyMap, baselineMap, eps=np.spacing(1.0)):\n",
    "    \"\"\"\n",
    "    Computes the _Image Based_ KL-divergence between two different saliency\n",
    "    maps when viewed as distributions: it is a non-symmetric measure\n",
    "    of the information lost when saliencyMap is used to estimate a 'true'\n",
    "    distribution.\n",
    "\n",
    "    created: Zoya Bylinskii, Aug 2014\\\\\n",
    "    python-version by: Dario Zanca/Pierre-Adrien Fons, 2017-20\n",
    "\n",
    "    Arguments:\n",
    "        saliencyMap: Grayscale image of a saliency map.\n",
    "        baselineMap: Grayscale image of a baseline saliency map to compare\n",
    "            saliencyMap to.\n",
    "\n",
    "    Returns:\n",
    "        KL divergence score (Non negative).\n",
    "    \"\"\"\n",
    "\n",
    "    if saliencyMap.shape != baselineMap.shape:\n",
    "        saliencyMap = cv2.resize(saliencyMap, np.shape(baselineMap)[:2][::-1])\n",
    "\n",
    "    if saliencyMap.any():\n",
    "        saliencyMap = sum_normalize(saliencyMap)\n",
    "    if baselineMap.any():\n",
    "        baselineMap = sum_normalize(baselineMap)\n",
    "\n",
    "    logp_model = np.log(saliencyMap + eps)\n",
    "    logp_gt = np.log(baselineMap + eps)\n",
    "    score = baselineMap * (logp_gt - logp_model)\n",
    "\n",
    "    return score.sum()\n",
    "\n",
    "def NSS(saliencyMap, fixationMap):\n",
    "    \"\"\"\n",
    "    This finds the normalized scanpath saliency (NSS) of a saliency map.\\\\\n",
    "    NSS is the average of the response values at human eye positions in a model\n",
    "    saliency map that has been normalized to have zero mean and unit standard\n",
    "    deviation.\n",
    "\n",
    "    created: Zoya Bylinskii, Aug 2014\\\\\n",
    "    python-version by: Dario Zanca/Pierre-Adrien Fons, 2017-20\n",
    "\n",
    "    Arguments:\n",
    "        saliencyMap: Saliency map (grayscale).\n",
    "        fixationMap: Ground truth fixation map (binary matrix).\n",
    "\n",
    "    Returns:\n",
    "        NSS score (0 : Chance, >0 : correspondance above Chance, <0 : anti\n",
    "            correspondance).\n",
    "    \"\"\"\n",
    "\n",
    "    if saliencyMap.shape != np.shape(fixationMap):\n",
    "        saliencyMap = cv2.resize(saliencyMap, np.shape(fixationMap)[:2][::-1])\n",
    "\n",
    "    saliencyMap = np.exp(log_density(saliencyMap))\n",
    "\n",
    "    mean = saliencyMap.mean()\n",
    "    std = saliencyMap.std()\n",
    "\n",
    "    value = saliencyMap[fixationMap.astype(bool)]\n",
    "\n",
    "    value -= mean\n",
    "    value /= std\n",
    "\n",
    "    return value.mean()\n",
    "\n",
    "def CC(saliencyMap1, saliencyMap2):\n",
    "    \"\"\"\n",
    "    Computes the linear correlation coefficient between two different\n",
    "    saliency maps (also called Pearson's linear coefficient).\n",
    "\n",
    "    Arguments:\n",
    "        saliencyMap1: Grayscale Saliency map.\n",
    "        saliencyMap2: Grayscale Saliency map.\n",
    "\n",
    "    Returns:\n",
    "        Linear correlation coefficient ([-1, 1]).\n",
    "    \"\"\"\n",
    "\n",
    "    if saliencyMap1.shape != saliencyMap2.shape:\n",
    "        saliencyMap1 = cv2.resize(saliencyMap1, np.shape(saliencyMap2)[:2][::-1])\n",
    "\n",
    "    saliencyMap1 = std_normalize(saliencyMap1)\n",
    "    saliencyMap2 = std_normalize(saliencyMap2)\n",
    "\n",
    "    return np.corrcoef(saliencyMap1.reshape(-1), saliencyMap2.reshape(-1))[0, 1]\n",
    "\n",
    "def similarity(pred_sal, gt_sal):\n",
    "    \"\"\"\n",
    "    This finds the similarity between two different saliency maps when\n",
    "    viewed as distributions (equivalent to histogram intersection).\n",
    "\n",
    "    score=1 means the maps are identical\n",
    "    score=0 means the maps are completely opposite\n",
    "\n",
    "    \"SIM is very sensitive to missing values, and penalizes predictions that\n",
    "    fail to account for all of the ground truth density.\"\n",
    "\n",
    "    Arguments:\n",
    "        pred_sal: Predicted saliency map (grayscale).\n",
    "        gt_sal: Ground truth saliency map (grayscale).\n",
    "\n",
    "    Returns:\n",
    "        Score of similarity [0, 1] between the two input saliency maps.\n",
    "    \"\"\"\n",
    "    if pred_sal.shape != gt_sal.shape:\n",
    "        pred_sal = cv2.resize(pred_sal, gt_sal.shape[:2][::-1])\n",
    "\n",
    "    # (1) first normalize the map values to lie between 0-1 this is done so\n",
    "    # that models that assign a nonzero value to every pixel do not get an\n",
    "    # artificial performance boost.\n",
    "    # (2) then make sure that the map is normalized to sum to 1 so that the\n",
    "    # maximum value of score will be 1.\n",
    "    if pred_sal.any():\n",
    "        pred_sal = range_normalize(pred_sal)\n",
    "        pred_sal = sum_normalize(pred_sal)\n",
    "\n",
    "    if gt_sal.any():\n",
    "        gt_sal = range_normalize(gt_sal)\n",
    "        gt_sal = sum_normalize(gt_sal)\n",
    "\n",
    "    diff = np.minimum(pred_sal, gt_sal)\n",
    "    return np.sum(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_all_observers(dir_path, img_name):\n",
    "    \"\"\"\n",
    "    List all eye-tracking data files related to a particular image.\n",
    "    \n",
    "    :param dir_path: str, the path to the directory in which the dataset is stored.\n",
    "    :param img_name: str, the name of the image for which we want to gather eye-tracking data.\n",
    "                     This must be of the form img.trn.xxx or img.tst.xxx\n",
    "    :return list_all_files: list, containing the paths to all the relevant eye-tracking files.\n",
    "    \"\"\"\n",
    "    list_all_files = glob.glob(os.path.join(dir_path, 'Data/**/*' + img_name + '.*'), recursive=True)\n",
    "    assert list_all_files, \"List of eye-tracking files seem to be empty. Check directory or image name.\"\n",
    "    return list_all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506457f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fixmap(list_obs_files, img_w, img_h, factor_x, factor_y, t_begin=0, t_end=15):\n",
    "    \"\"\"\n",
    "    Create a fixation map based on raw eye-tracking data.\n",
    "    \n",
    "    :param list_obs_files: list, a list of paths to the eye-tracking files of each observer for the considered image\n",
    "    :param img_w: int, the width of the image, in pixels\n",
    "    :param imw_h: int, the height of the image, in pixels\n",
    "    :param factor_x: float, the ratio of the horizontal resolution to the horizontal size of the screen used in the eye-tracking experiment\n",
    "    :param factor_y: float, the ratio of the vertical resolution to the vertical size of the screen used in the eye-tracking experimen\n",
    "    :param t_begin: float, the start of the time slice to consider, in s.\n",
    "    :param t_end: float, the end of the time slice to consider, in s.\n",
    "    :return fixmap: numpy array, the fixation map.\n",
    "    \"\"\"\n",
    "    # First, let's initialize the fixation map.\n",
    "    fixmap = np.zeros((img_h, img_w))\n",
    "    sigma_filter = 5\n",
    "    for obs in list_obs_files:\n",
    "        #load fixation points\n",
    "        mat_data = loadmat(obs)\n",
    "        data_key = mat_data['fixLocs']\n",
    "        \n",
    "        #create fixation map by convolving a gaussian filter\n",
    "        for x in range(len(data_key)):\n",
    "            for y in range(len(data_key[x])):\n",
    "                if data_key[x][y] != 0 and 0 < x < img_h and 0 < y < img_w:\n",
    "                    fixmap[x, y] = 1\n",
    "        fixmap = gaussian_filter(fixmap, sigma=sigma_filter)\n",
    "        fixmap = (fixmap - np.min(fixmap)) / (np.max(fixmap) - np.min(fixmap))\n",
    "                    \n",
    "    \n",
    "    return fixmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02184ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ppda(distance, h_res, v_res, screen_w, screen_h):\n",
    "    \"\"\"\n",
    "    Compute the number of pixels per degree of visual angle based on the experimental conditions.\n",
    "    \n",
    "    :param distance: int, the distance between the observer and the screen (in mm)\n",
    "    :param h_res: int, the horizontal resolution of the screen\n",
    "    :param v_res: int, the vertical resolution of the screen\n",
    "    :param screen_w: int, the width of the screen (in mm)\n",
    "    :param screen_h: int, the height of the screen (in mm)\n",
    "    :return horizontal_ppda: float, the number of pixel per degree of visual angle\n",
    "    \"\"\"    \n",
    "    ###### TODO ######\n",
    "    pxl_density_x = h_res / screen_w\n",
    "    pxl_density_y = v_res / screen_h\n",
    "    \n",
    "    # print(str(pxl_density_x) + ' ' + str(pxl_density_y))\n",
    "    \n",
    "    d = 2 * distance * math.tan(np.deg2rad(0.5))\n",
    "    horizontal_ppda = d * ((pxl_density_x + pxl_density_y) / 2)\n",
    "    \n",
    "    \n",
    "    return horizontal_ppda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93855239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def salmap_from_fixmap(fixmap, ppda):\n",
    "    \"\"\"\n",
    "    Generate a visual saliency map, based on the fixation map.\n",
    "    \n",
    "    :param fixmap: numpy array, the fixation map\n",
    "    :param ppda: float, the number of pixels per degree of visual angle\n",
    "    :return salmap: numpy array, the visual saliency map\n",
    "    \"\"\"\n",
    "    \n",
    "    sigma = ppda / np.sqrt(2)\n",
    "    \n",
    "    salmap = gaussian_filter(fixmap, sigma=sigma)\n",
    "\n",
    "    ###### TODO ######\n",
    "    return salmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b473a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "achanta = Achanta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c7f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of one image\n",
    "\n",
    "files = get_files_all_observers(PATH_DATA, \"cockpit/sun_cdtbrxessaoxghds\")\n",
    "fixmap = create_fixmap(files, RESO_X, RESO_Y, FACTOR_X, FACTOR_Y)\n",
    "img = mpimg.imread(os.path.join(PATH_DATA, \"Stimuli/cockpit/sun_cdtbrxessaoxghds.jpg\"))\n",
    "ppda = compute_ppda(415.8, RESO_X, RESO_Y, 270, 203)\n",
    "salmap = salmap_from_fixmap(fixmap, ppda)\n",
    "salmap_achanta = achanta.get_salmap(img)\n",
    "salmap_deep = mpimg.imread(os.path.join(PATH_DEEP, \"sun_cdtbrxessaoxghds.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a1bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent = [0, fixmap.shape[1], 0, fixmap.shape[0]]\n",
    "\n",
    "fig, axarr = plt.subplots(1, 5, figsize=(15, 15))\n",
    "axarr[0].imshow(img)\n",
    "axarr[0].set_title('Image')\n",
    "\n",
    "axarr[1].imshow(img, cmap = 'viridis', extent = extent)\n",
    "axarr[1].imshow(fixmap, cmap = 'plasma', alpha = 0.8, extent = extent)\n",
    "axarr[1].set_title('Fixation points')\n",
    "\n",
    "axarr[2].imshow(img, cmap = 'viridis', extent = extent)\n",
    "axarr[2].imshow(salmap, cmap = 'plasma', alpha = 0.8, extent = extent)\n",
    "axarr[2].set_title('Ground truth')\n",
    "\n",
    "axarr[3].imshow(img, cmap = 'viridis', extent = extent)\n",
    "axarr[3].imshow(salmap_achanta, cmap = 'plasma', alpha = 0.8, extent = extent)\n",
    "axarr[3].set_title('Saliency map Achanta')\n",
    "\n",
    "axarr[4].imshow(img, cmap = 'viridis', extent = extent)\n",
    "axarr[4].imshow(salmap_deep, cmap = 'plasma', alpha = 0.8, extent = extent)\n",
    "axarr[4].set_title('MSINet model')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd8a7d",
   "metadata": {},
   "source": [
    "## Achanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of folder names\n",
    "folder_names = [\"airport_terminal\", \"amusement_park\", \"badlands\", \"bathroom\", \"bedroom\", \"bridge\", \"castle\", \"cockpit\", \"conference_room\", \"dining_room\", \"golf_course\", \"highway\", \"house\", \"kitchen\", \"lighthouse\", \"living_room\", \"mountain\", \"pasture\",\n",
    "                \"playground\", \"skyscraper\", \"tower\"] \n",
    "\n",
    "aucBorji = []\n",
    "klDiv = []\n",
    "nss = []\n",
    "cc = []\n",
    "sim = []\n",
    "\n",
    "\n",
    "# Define function to calculate metrics\n",
    "def calculate_metrics_for_folder(folder_name):\n",
    "    number_of_images = 0\n",
    "    Borji_mean = 0\n",
    "    K1_mean = 0\n",
    "    NSS_mean = 0\n",
    "    CC_mean = 0\n",
    "    similarity_mean = 0\n",
    "    \n",
    "    # Define the path to the folder\n",
    "    full_folder_path = os.path.join(PATH_DATA + \"/Stimuli\", folder_name)\n",
    "\n",
    "    # Get all image files in the folder\n",
    "    folder_files = [f for f in os.listdir(full_folder_path) if f.endswith(\".jpg\")]\n",
    "    \n",
    "    # Iterate through each file in the folder\n",
    "    for file_name in folder_files:\n",
    "        file_path = os.path.join(full_folder_path, file_name)\n",
    "        files = get_files_all_observers(PATH_DATA, folder_name + \"/\" + file_name.split('.')[0])\n",
    "        if(files is None):\n",
    "            continue\n",
    "        # Create fixation map, read image, etc. (use your existing code)\n",
    "        fixmap = create_fixmap(files, RESO_X, RESO_Y, FACTOR_X, FACTOR_Y)\n",
    "        img = mpimg.imread(file_path)\n",
    "        ppda = compute_ppda(415.8, RESO_X, RESO_Y, 270, 203)\n",
    "        salmap_achanta = achanta.get_salmap(img)\n",
    "        salmap = salmap_from_fixmap(fixmap, ppda)\n",
    "        #print(\"Here\")\n",
    "        # Calculate metrics\n",
    "        score1b, _, _ = AUC_Borji(saliencyMap=salmap_achanta, fixationMap=fixmap)\n",
    "        klScore = kl_divergence(saliencyMap=salmap_achanta, baselineMap=salmap)\n",
    "        nssScore1 = NSS(saliencyMap=salmap_achanta, fixationMap=fixmap)\n",
    "        ccScore = CC(saliencyMap1=salmap_achanta, saliencyMap2=salmap)\n",
    "        similarityScore = similarity(pred_sal=salmap_achanta, gt_sal=salmap)\n",
    "\n",
    "        # Update mean values\n",
    "        number_of_images += 1\n",
    "        Borji_mean += score1b\n",
    "        K1_mean += klScore\n",
    "        NSS_mean += nssScore1 \n",
    "        CC_mean += ccScore\n",
    "        similarity_mean += similarityScore\n",
    "    \n",
    "    # Calculate means for the folder\n",
    "    Borji_mean /= number_of_images\n",
    "    K1_mean /= number_of_images\n",
    "    NSS_mean /= number_of_images\n",
    "    CC_mean /= number_of_images\n",
    "    similarity_mean /= number_of_images\n",
    "\n",
    "    aucBorji.append(Borji_mean)\n",
    "    klDiv.append(K1_mean)\n",
    "    nss.append(NSS_mean)\n",
    "    cc.append(CC_mean)\n",
    "    sim.append(similarity_mean)\n",
    "        \n",
    "\n",
    "    # Print metrics with their names\n",
    "    print(f\"Metrics for folder '{folder_name}':\")\n",
    "    print(f\"Borji Mean: {Borji_mean}\")\n",
    "    print(f\"K1 Mean: {K1_mean}\")\n",
    "    print(f\"NSS Mean: {NSS_mean}\")\n",
    "    print(f\"CC Mean: {CC_mean}\")\n",
    "    print(f\"Similarity Mean: {similarity_mean}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Iterate through each folder and calculate metrics\n",
    "for folder_name in folder_names:\n",
    "    calculate_metrics_for_folder(folder_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fbeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "# Plot averages\n",
    "plt.plot(folder_names, aucBorji, label='AUC Borji', marker='o')\n",
    "plt.plot(folder_names, klDiv, label='KL divergence', marker='s')\n",
    "plt.plot(folder_names, nss, label='NSS - normalized scanpath saliency', marker='p')\n",
    "plt.plot(folder_names, cc, label='linear correlation coefficient', marker='X')\n",
    "plt.plot(folder_names, sim, label='similarity', marker='D')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Value')\n",
    "plt.title('')\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cb9e59",
   "metadata": {},
   "source": [
    "## MSINet model\n",
    "https://github.com/alexanderkroner/saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b948bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotEvolution(files):\n",
    "    \n",
    "    aucBorji = []\n",
    "    klDiv = []\n",
    "    nss = []\n",
    "    cc = []\n",
    "    sim = []\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        fixmap = create_fixmap([file], RESO_X, RESO_Y, FACTOR_X, FACTOR_Y)\n",
    "        ppda = compute_ppda(415.8, RESO_X, RESO_Y, 270, 203)\n",
    "        gt = salmap_from_fixmap(fixmap, ppda)\n",
    "        \n",
    "        file_name_without_extension, file_extension = os.path.splitext(file)\n",
    "        img_name = file_name_without_extension.split(\"_\")[-1]\n",
    "        pred = mpimg.imread(os.path.join(PATH_DEEP,\"sun_\" + img_name + \".jpeg\"))\n",
    "        pred = pred / 255\n",
    "\n",
    "        score1b, fpr1, tpr1 = Lab_2_VA.AUC_Borji(saliencyMap=pred, fixationMap=fixmap)\n",
    "\n",
    "        klScore = kl_divergence(saliencyMap=pred, baselineMap=gt)\n",
    "\n",
    "        nssScore1 = NSS(saliencyMap=pred, fixationMap=fixmap)\n",
    "\n",
    "        ccScore = CC(saliencyMap1=gt, saliencyMap2=pred)\n",
    "\n",
    "        similarityScore = similarity(pred_sal=gt, gt_sal=pred)\n",
    "\n",
    "        aucBorji.append(score1b)\n",
    "        klDiv.append(klScore)\n",
    "        nss.append(nssScore1)\n",
    "        cc.append(ccScore)\n",
    "        sim.append(similarityScore)\n",
    "        \n",
    "    return aucBorji, klDiv, nss, cc, sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d01335",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = os.listdir(PATH_DATA + \"/Stimuli\")\n",
    "\n",
    "# Use a list comprehension to filter out only directories\n",
    "directories = [content for content in contents if os.path.isdir(os.path.join(PATH_DATA + \"/Stimuli\", content))]\n",
    "\n",
    "aucBorjiScores = []\n",
    "klDivScores = []\n",
    "nssScores = []\n",
    "ccScores = []\n",
    "simScores = []\n",
    "\n",
    "for directory in directories:\n",
    "    list_all_files = glob.glob(os.path.join(PATH_DATA, 'Data/'+ directory + '/' + '*.*'), recursive=True)\n",
    "\n",
    "    aucBorji, klDiv, nss, cc, sim = plotEvolution(list_all_files)\n",
    "    \n",
    "    aucBorjiScores.append(aucBorji)\n",
    "    klDivScores.append(klDiv)\n",
    "    nssScores.append(nss)\n",
    "    ccScores.append(cc)\n",
    "    simScores.append(sim)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2855bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savez('aucBorjiScores.npz', *aucBorjiScores)\n",
    "np.savez('klDivScores.npz', *klDivScores)\n",
    "np.savez('nssScores.npz', *nssScores)\n",
    "np.savez('ccScores.npz', *ccScores)\n",
    "np.savez('simScores.npz', *simScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331acf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistics(metricScores):\n",
    "\n",
    "    # Initialize lists to store mean and average values for each array\n",
    "    mean_values = []\n",
    "    average_values = []\n",
    "\n",
    "    for i in range(len(metricScores)):\n",
    "        # Load each array\n",
    "        loaded_array = metricScores[i]\n",
    "        if (loaded_array.size != 0):\n",
    "\n",
    "            # Compute mean and average for the loaded array\n",
    "            mean_value = np.mean(loaded_array)\n",
    "            average_value = np.average(loaded_array)\n",
    "\n",
    "            # Append the results to the lists\n",
    "            mean_values.append(mean_value)\n",
    "            average_values.append(average_value)\n",
    "\n",
    "    return mean_values, average_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1349061",
   "metadata": {},
   "outputs": [],
   "source": [
    "borji_mean, borji_avg = compute_statistics(aucBorjiScores)\n",
    "klDiv_mean, klDiv_avg = compute_statistics(klDivScores)\n",
    "nss_mean, nss_avg = compute_statistics(nssScores)\n",
    "cc_mean, cc_avg = compute_statistics(ccScores)\n",
    "sim_mean, sim_avg = compute_statistics(simScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = os.listdir(PATH_DATA + \"/Stimuli\")\n",
    "directories = [content for content in contents if os.path.isdir(os.path.join(PATH_DATA + \"/Stimuli\", content))]\n",
    "directories.remove('salicon')\n",
    "print(directories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd35b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot averages\n",
    "plt.plot(directories, borji_avg, label='AUC Borji', marker='o')\n",
    "plt.plot(directories, klDiv_avg, label='KL divergence', marker='s')\n",
    "plt.plot(directories, nss_avg, label='NSS - normalized scanpath saliency', marker='p')\n",
    "plt.plot(directories, cc_avg, label='linear correlation coefficient', marker='X')\n",
    "plt.plot(directories, sim_avg, label='similarity', marker='D')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Value')\n",
    "plt.title('')\n",
    "\n",
    "# Rotate x-axis labels for better visibility\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde2fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
